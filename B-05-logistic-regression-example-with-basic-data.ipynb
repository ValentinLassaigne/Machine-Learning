{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c97b385f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# exemple de régression logistique avec $sklearn$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e829426",
   "metadata": {},
   "source": [
    "## on importe les bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887f781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcec5f83",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## on lit les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ad8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"exam.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['first_exam', 'second_exam', 'admitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac220af",
   "metadata": {},
   "outputs": [],
   "source": [
    "exam = pd.read_csv(filename, names=columns, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40b909",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "exam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e197c1f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "exam[['first_exam', 'second_exam']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0babff0e",
   "metadata": {},
   "source": [
    "## on plot les histogrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01be428",
   "metadata": {},
   "outputs": [],
   "source": [
    "exam[['first_exam', 'second_exam', 'admitted']].hist(figsize=(5, 5), bins=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd3f13d",
   "metadata": {},
   "source": [
    "## on plot les boîtes à moustache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c43b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exam[['first_exam', 'second_exam']].boxplot(figsize=(4, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363cf603",
   "metadata": {},
   "source": [
    "## on compte les élèves au dessous et au dessus de la moyenne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c845f",
   "metadata": {},
   "source": [
    "### premier examen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d408fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(exam['first_exam'] < 50), np.sum(exam['first_exam'] >= 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd43fb47",
   "metadata": {},
   "source": [
    "### second examen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ffaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(exam['second_exam'] < 50), np.count_nonzero(exam['second_exam'] >= 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2436c7ec",
   "metadata": {},
   "source": [
    "## on plot les notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fd1d77",
   "metadata": {},
   "source": [
    "### avec le paramètre `c` de `scatter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ae9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = plt.scatter(exam['first_exam'], exam['second_exam'], c=exam['admitted'], cmap=\"winter\",\n",
    "                     marker='.');\n",
    "plt.xlabel('first_exam')\n",
    "plt.ylabel('second_exam')\n",
    "\n",
    "plt.legend(*scatter.legend_elements()); # les labels pour la légende;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c2415c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## on crée un modèle de régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e873095",
   "metadata": {},
   "source": [
    "Le modèle est un modèle linéaire avec deux variables (les notes des deux examens) et un terme constant\n",
    "$$\\theta_0 + \\theta_1\\;  note\\_first\\_exam + \\theta_2\\;  note\\_second\\_exam = 0$$  \n",
    "on va rechercher par l'apprentissage les coefficients $\\theta_0$, $\\theta_1$ et $\\theta_2$ de la droite qui sépare le mieux les deux nuages de points `admitted` et `refused`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79226390",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(exam['first_exam'], exam['second_exam'], c=exam['admitted'], marker='.')\n",
    "plt.plot([40, 100], [100, 36]);\n",
    "plt.plot([30, 80], [100, 30]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e13a16",
   "metadata": {},
   "source": [
    "on recherche la droite qui fait la plus petite erreur  \n",
    "qui classifie bien un maximum de points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e83b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b4eade",
   "metadata": {},
   "source": [
    "on crée un objet de type régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95d188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(solver='newton-cg') # par exemple newton avec gradien conjugué"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6743a3d8",
   "metadata": {},
   "source": [
    "notons que vous allez pouvoir fixer un grand nombre de paramètres dont le solver, la fonction de perte... (voir le help de `linear_model.LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc148be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_model.LogisticRegression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb3d20",
   "metadata": {},
   "source": [
    "## les données d'entrée et de sorties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ba5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = exam[['first_exam', 'second_exam']]\n",
    "y = exam['admitted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b9591d",
   "metadata": {},
   "source": [
    "## on `fit` le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d732b9",
   "metadata": {},
   "source": [
    "pour déterminer les $\\theta_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac7440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642167fb",
   "metadata": {},
   "source": [
    "### le terme constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f5beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_ # theta0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9addb3",
   "metadata": {},
   "source": [
    "### les coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e938ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_ # theta1 et theta2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302ebf5d",
   "metadata": {},
   "source": [
    "### équation de la droite qui sépare les deux classes $admitted$ et $refused$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcce2ca7",
   "metadata": {},
   "source": [
    "   - $\\theta_0 + \\theta_1\\;  note\\_first\\_exam + \\theta_2\\;  note\\_second\\_exam = 0$\n",
    "\n",
    "où\n",
    "\n",
    "   - $\\theta_0 = model.intercept\\_[0]$\n",
    "   - $\\theta_1 = model.coef\\_[0][0]$\n",
    "   - $\\theta_2 = model.coef\\_[0][1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ba9c09",
   "metadata": {},
   "source": [
    "donc $y = -(\\theta_0 + \\theta_1 x))/\\theta_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af48920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_line(x):\n",
    "    return -(model.intercept_[0] + model.coef_[0][0]*x)/model.coef_[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d2891",
   "metadata": {},
   "source": [
    "la fonction `y_line` s'applique à un argument, on la vectorise pour qu'elle s'applique à un vecteur d'arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_line_vect = np.vectorize(y_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e388c4c4",
   "metadata": {},
   "source": [
    "### on plot la fonction de prédiction trouvée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e02868",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(exam['first_exam'], exam['second_exam'], c=exam['admitted'], marker='.')\n",
    "plt.plot([30, 100], y_line_vect([30, 100]));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d631fd56",
   "metadata": {},
   "source": [
    "## les prédictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a90210f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### calcul *à-la-main*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca1542",
   "metadata": {},
   "source": [
    "Dans nos prédictions, les admis sont les points au dessus de la droite et les refusés sont les points au dessous de la droite\n",
    "\n",
    "les admis sont les points tels que  \n",
    "$\\theta_0 + \\theta_1\\;  note\\_first\\_exam + \\theta_2\\;  note\\_second\\_exam >= 0$  \n",
    "\n",
    "les refusés sont les points tels que  \n",
    "$\\theta_0 + \\theta_1\\;  note\\_first\\_exam + \\theta_2\\;  note\\_second\\_exam < 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc6613",
   "metadata": {},
   "outputs": [],
   "source": [
    "exam['admitted'][0:2] # les 2 premiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ed81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = (model.intercept_[0] \n",
    "             + model.coef_[0][0] * exam['first_exam']\n",
    "             + model.coef_[0][1] * exam['second_exam']) >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcde8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c4f396",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### calcul avec $sklearn$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd535119",
   "metadata": {},
   "source": [
    "naturellement on peut laisser `sklearn` calculer les prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4097f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394e8378",
   "metadata": {},
   "source": [
    "on vérifie que ce sont les mêmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299fa94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(y_predict == predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d152ee",
   "metadata": {
    "lines_to_next_cell": 0,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### on trace les prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952520ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# les mesurés sont en vert et rouge\n",
    "\n",
    "admitted = exam.loc[exam['admitted'] == 1]\n",
    "refused  = exam.loc[exam['admitted'] == 0]\n",
    "\n",
    "plt.plot(admitted['first_exam'], admitted['second_exam'], 'go', label='admitted')\n",
    "plt.plot(refused['first_exam'],  refused['second_exam'],  'ro', label='refused')\n",
    "\n",
    "# les prédits sont en bleu et jaune\n",
    "\n",
    "admitted_predict = exam.loc[y_predict == 1]\n",
    "refused_predict = exam.loc[y_predict == 0]\n",
    "\n",
    "plt.plot(admitted_predict['first_exam'], admitted_predict['second_exam'], 'b.', label='predict admitted')\n",
    "plt.plot(refused_predict['first_exam'],  refused_predict['second_exam'],  'y.', label='predict refused')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b56335",
   "metadata": {},
   "source": [
    "on voit de bonnes prédictions\n",
    "* bleu cerclés de vert sont les bien prédits `admitted`\n",
    "* jaunes cerclés de rouge sont les bien prédits `refused`\n",
    "\n",
    "on voit des erreurs à la frontière\n",
    "* les jaunes cerclés de vert sont les prédits refusés mais en fait admis\n",
    "* les bleu cerclés de rouge sont les prédits acceptés mais en fait refusés\n",
    "\n",
    "... on en discute juste après"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628dc9b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## les erreurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b44d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### on peut calculer le taux d'erreur à-la-main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07776799",
   "metadata": {},
   "source": [
    "le nombre des mauvaises classifications toutes classes confondues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d5b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(exam['admitted'] == y_predict)/100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c839361f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### on peut le calculer avec `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2315074",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a6b36f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## les résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7715dd61",
   "metadata": {},
   "source": [
    "nos prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cc7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc973d",
   "metadata": {},
   "source": [
    "### les vrais positifs\n",
    "\n",
    "on les a prédits `admitted` (`1`) ils étaient `admitted` (`1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cb30f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = exam.loc[(y_predict == 1) & (exam['admitted'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f45d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(true_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181afc5f",
   "metadata": {},
   "source": [
    "### les vrais négatifs\n",
    "\n",
    "on les a prédits `refused` (`0`) ils étaient `refused` (`0`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9789a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_negative = exam.loc[(y_predict == 0) & (exam['admitted'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd5b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(true_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ffe1f5",
   "metadata": {},
   "source": [
    "### les faux positifs\n",
    "\n",
    "on les a prédits `admitted` (`1`) alors qu'ils étaient `refused` (`0`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9559a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive = exam.loc[(y_predict == 1) & (exam['admitted'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6067ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(false_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce0482a",
   "metadata": {},
   "source": [
    "### les faux négatifs\n",
    "on les a prédits `refused` (`0`) alors qu'ils étaient `admitted` (`1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08165934",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negative = exam.loc[(y_predict == 0) & (exam['admitted'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ce4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(false_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b1bc2e",
   "metadata": {},
   "source": [
    "### matrice de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca36ee65",
   "metadata": {},
   "source": [
    "la matrice de confusion de notre exemple:\n",
    "\n",
    "| | admitted | refused|\n",
    "| --| --| --|\n",
    "| predict admitted |  55 | 6 | \n",
    "| predict refused | 5 | 34 |\n",
    "\n",
    "donne une estimation de la qualité de notre modèle de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4024d2ae",
   "metadata": {},
   "source": [
    "**plusieurs mesures statistiques sont définies**:\n",
    "\n",
    "**True positive rate**, **Recall**, **Sensitivity**, **probability of detection** $= \\dfrac{vrai \\, positif}{vrai\\, positif\\, +\\, faux\\, négatif}$ \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**False positive rate**, **Fall-out**, **probability of false alarm** $= \\dfrac{faux\\, positif}\n",
    "{faux\\, positif\\, +\\, vrai\\, négatif}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa6d2f8",
   "metadata": {},
   "source": [
    "### avec `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbf4416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce4c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = confusion_matrix(y_true=exam['admitted'], y_pred=y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cce966",
   "metadata": {},
   "outputs": [],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e43bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "C[0, 0] # vrais négatifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5668d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "C[0, 1] # faux positifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a45c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "C[1, 0] # faux négatifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f982e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "C[1, 1] # vrais positifs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0589666a",
   "metadata": {},
   "source": [
    "END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
